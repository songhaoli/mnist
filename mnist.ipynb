{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset with KNN, SVM, NN and CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "npDXna96IlSN"
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Xk8dyjZIlTH"
   },
   "source": [
    "Manual loading MNIST for offline access.\n",
    "\n",
    "Original files @ http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtvL6e9LIlTf"
   },
   "outputs": [],
   "source": [
    "# def read_idx(filename):\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "#         shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "#         return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "# files = ['train-images-idx3-ubyte','train-labels-idx1-ubyte','t10k-images-idx3-ubyte','t10k-labels-idx1-ubyte']\n",
    "# arrays = []\n",
    "\n",
    "# for file in files:\n",
    "#     arrays.append(read_idx(file))\n",
    "\n",
    "# (x_train, y_train, x_test, y_test) = tuple(arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZ_Z1VK3IlUR"
   },
   "source": [
    "Loading MNIST from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kh_ZfH9xIlUd"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2L769w24ZM4L"
   },
   "source": [
    "Normalize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uN2v_zA1ZDgt"
   },
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#y_train = tf.keras.utils.to_categorical(y_train)\n",
    "#y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaRjkzNQQzW7"
   },
   "source": [
    "KNN model\n",
    "\n",
    "Taking too long to train.\n",
    "\n",
    "With the reduced train_size = 5000 and test_size = 500, there is significant over-fitting.\n",
    "\n",
    "Score on training data = ~96%\n",
    "\n",
    "Score on test data = ~91%\n",
    "\n",
    "We expect the overfitting to decrease with the full sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "icEjUajcQyJW"
   },
   "outputs": [],
   "source": [
    "def knn_model():\n",
    "  model = neighbors.KNeighborsClassifier(n_neighbors=5, p=2)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 55563,
     "status": "ok",
     "timestamp": 1559313541703,
     "user": {
      "displayName": "Songhao Li",
      "photoUrl": "https://lh5.googleusercontent.com/-OfGLJSyvUoo/AAAAAAAAAAI/AAAAAAAAFdw/us6qe5P0IwE/s64/photo.jpg",
      "userId": "15480945800598553175"
     },
     "user_tz": 240
    },
    "id": "VpKB1u1aRJtJ",
    "outputId": "b0b57a59-e7ba-4473-b661-b4fc4a1f21c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on the training data: 0.9608\n",
      "Score on the test data: 0.91\n"
     ]
    }
   ],
   "source": [
    "train_size_knn = 5000\n",
    "test_size_knn = 500\n",
    "\n",
    "x_train_knn = x_train[:train_size_knn].reshape(train_size_knn, 28*28)\n",
    "y_train_knn = y_train[:train_size_knn]\n",
    "x_test_knn = x_test[:test_size_knn].reshape(test_size_knn, 28*28)\n",
    "y_test_knn = y_test[:test_size_knn]\n",
    "\n",
    "### Uncomment to run knn\n",
    "\n",
    "# knn_model = knn_model()\n",
    "# knn_model.fit(x_train_knn, y_train_knn)\n",
    "\n",
    "# print('Score on the training data: {}'.format(knn_model.score(x_train_knn, y_train_knn)))\n",
    "# print('Score on the test data: {}'.format(knn_model.score(x_test_knn, y_test_knn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQ3F_yMbT9mT"
   },
   "source": [
    "SVM model\n",
    "\n",
    "Taking too long to train.\n",
    "\n",
    "With the reduced train_size = 5000 and test_size = 500, there is significant over-fitting.\n",
    "\n",
    "Score on training data = ~99%\n",
    "\n",
    "Score on test data = ~95%\n",
    "\n",
    "We expect the overfitting to decrease with the full sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0uon-v31T8pt"
   },
   "outputs": [],
   "source": [
    "def svm_model():\n",
    "  model = svm.SVC(C=1, kernel='rbf',gamma=0.02)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qoTIA3-FnClO"
   },
   "outputs": [],
   "source": [
    "train_size_svm = 5000\n",
    "test_size_svm = 500\n",
    "\n",
    "x_train_svm = x_train[:train_size_svm].reshape(train_size_svm, 28*28)\n",
    "y_train_svm = y_train[:train_size_svm]\n",
    "x_test_svm = x_test[:test_size_svm].reshape(test_size_svm, 28*28)\n",
    "y_test_svm = y_test[:test_size_svm]\n",
    "\n",
    "### uncomment to run svm\n",
    "\n",
    "# svm_model = svm_model()\n",
    "# svm_model.fit(x_train_svm, y_train_svm)\n",
    "\n",
    "# print('Score on the training data: {}'.format(svm_model.score(x_train_svm, y_train_svm)))\n",
    "# print('Score on the test data: {}'.format(svm_model.score(x_test_svm, y_test_svm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNE03jJYs4AP"
   },
   "source": [
    "Baseline NN model\n",
    "\n",
    "Score on test data = ~97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sO3qbQoys7eT"
   },
   "outputs": [],
   "source": [
    "def base_model():\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "  # Add some dropout to reduce overfitting\n",
    "  model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "  model.add(tf.keras.layers.Dense(10, kernel_initializer='normal', activation=tf.nn.softmax))\n",
    "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4zFZcB79uJPb"
   },
   "outputs": [],
   "source": [
    "### uncomment to run baseline neural network model\n",
    "\n",
    "# base_model = base_model()\n",
    "# base_model.fit(x_train, y_train, epochs=5)\n",
    "# base_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VPOqsfjpGhE"
   },
   "source": [
    "CNN Model\n",
    "\n",
    "Score on test data = ~99.3%\n",
    "\n",
    "There is still a lot of room to tune the (hyper)parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8yRodTzpRqh"
   },
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "  model = tf.keras.models.Sequential()\n",
    "  model.add(tf.keras.layers.Conv2D(64, padding = 'same', kernel_size=(3, 3), activation=tf.nn.relu, input_shape=(28, 28, 1)))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=2))\n",
    "  model.add(tf.keras.layers.Conv2D(64, padding = 'same', kernel_size=(3, 3), activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=2))\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "  model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "  model.add(tf.keras.layers.Dropout(0.5))\n",
    "  model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adadelta(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptRTEUW0pZeD"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 12\n",
    "\n",
    "### uncomment to run convolutional neural network model\n",
    "\n",
    "# cnn_model = cnn_model()\n",
    "# x_train_4d = np.expand_dims(x_train, axis=3)\n",
    "# x_test_4d = np.expand_dims(x_test, axis=3)\n",
    "# cnn_model.fit(x_train_4d, y_train, batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "# cnn_model.evaluate(x_test_4d, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNISTtest.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
